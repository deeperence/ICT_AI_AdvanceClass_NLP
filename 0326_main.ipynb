{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘', '미세', '먼지', '미세', '먼지']\n['오늘', '미세', '미세먼지', '먼지']\n['오늘', '미세먼지는', '어제', '미세먼지보다', '나빠요.']\n['오늘', '미세먼지는', '어제', '미세먼지보다', '나빠요', '.']\n원본 :  오늘 미세먼지는 어제 미세먼지보다 나빠요.\n어절 단위 분리 :  ['오늘', '미세먼지는', '어제', '미세먼지보다', '나빠요']\n형태소 분석 결과 :  ['미세먼지는', '아요', '보다', '어제', '먼지', '나쁘', '미세먼지보다', '미세', '오늘', '나빠요']\n명사 분석 결과 :  ['미세먼지는', '아요', '보다', '어제', '미세먼지', '먼지', '나쁘', '미세먼지보다', '미세', '오늘', '나빠요']\n어절(바이그램) 분석 :  ['미세', '나빠요', '미세먼지는', '먼지 보다', '는 어제', '보다', '미세 먼지', '먼지 는', '오늘', '오늘 미세', '어제', '미세먼지', '먼지', '보다 나쁘', '미세먼지보다', '아요', '아요 .', '나쁘 아요', '나쁘', '어제 미세']\n음절(바이그램) 분석 :  ['나빠', '지보', '미세', '나빠요', '세먼', '미세먼지는', '먼지 보다', '는 어제', '보다', '미세 먼지', '지는', '먼지 는', '오늘', '오늘 미세', '어제', '미세먼지', '먼지', '보다 나쁘', '미세먼지보다', '아요', '아요 .', '나쁘 아요', '빠요', '나쁘', '어제 미세']\n25\n"
     ]
    }
   ],
   "source": [
    "# 이 코드에서는 깨끗한 단어를 추출하기 위해 심화단계의 tokenize를 수행해 봅니다. (NLP를 위한 전처리)\n",
    "# 그동안 split()만 사용해 왔지만 다른 방법도 적용해 봅니다. 어느 feature가 좋은지 모르므로 최대한 많이 뽑아내는 것이 목적입니다. \n",
    "\n",
    "from konlpy.tag import Kkma # 형태소 분석기 중에는 kkma가 성능이 제일 좋음.\n",
    "ma = Kkma() # 형태소 분석기 인스턴스\n",
    "sentence = \"오늘 미세먼지는 어제 미세먼지보다 나빠요.\"\n",
    "\n",
    "# 명사를 뽑으라고 시키면 => 오늘, 미세, 먼지, 어제, 미세, 먼지가 뽑혀야 함.\n",
    "# ma.pos(sentence) # 형태소가 부착된(태깅된) 형태로 반환\n",
    "print([token[0] for token in ma.pos(sentence) if token[1].startswith(\"NN\")])\n",
    "print(ma.nouns(sentence)) # 명사만 뽑기\n",
    "\n",
    "# BOW => index term, Lexicon(dictionary)로 부르기도 함. \n",
    "# 문장 단위 -> 어절 단위 -> 형태소 단위 -> 품사(명사) 단위로 보고, 추가로 Ngram 단위로도 문장을 볼 예정\n",
    "# 일반적인 전처리 순서 : 토크나이징 -> Normalization(단어의 길이, 한국어의 경우 1음절 단위로 수행하기도 함)\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize # 두 개의 토큰화 모듈 임포트 \n",
    "\n",
    "# 구두점에 대한 처리만 빼고 비슷한 결과가 나올 것임.\n",
    "print(sentence.split()) # 단순히 split\n",
    "print(word_tokenize(sentence)) # 구두점도 별도로 분류를 했으므로 어절이 누구인지 찾을 수 있다.\n",
    "\n",
    "print(\"원본 : \", sentence)\n",
    "\n",
    "# tokenized data\n",
    "lexicon = list()\n",
    "th = 1 # 1음절보다 큰 문자를 고르기 위한 상수\n",
    "lexicon = [token for token in word_tokenize(sentence) if len(token) > th]\n",
    "print(\"어절 단위 분리 : \", lexicon)\n",
    "\n",
    "# 품사에 대해 태깅 작업 수행\n",
    "# print(ma.pos(sentence)) # 둘의 차이는 그렇게 크지 않다.\n",
    "for token in [token for token in word_tokenize(sentence) if len(token) > th]: # 명사 분류시 문제가 될 수 있으므로 토큰화한 후 수행\n",
    "    lexicon.extend([token[0] for token in ma.pos(token) if len(token[0]) > th]) # (단어, 품사) 튜플쌍으로 받기 위해 for문을 돌면서 형태소 분석. (ma.morphs() 함수를 사용하면 형태소만 반환받을 수 있음. )\n",
    "    # lexicon.extend([token[0] for token in ma.pos(token) if len(token[0]) > th] and token[1] in [\"NN\", \"NNG\"]) 등과 같이 and조건 옆에 원하는 품사를 넣어서 그 POS 태그에 해당하는 것들만 튜플쌍으로 받을 수도 있다. \n",
    "print(\"형태소 분석 결과 : \", list(set(lexicon))) # 필요없는 중복값을 날리기 위해 set()에 담음 \n",
    "\n",
    "for token in [token for token in word_tokenize(sentence) if len(token) > th]: # 명사 분류시 문제가 될 수 있으므로 토큰화한 후 수행\n",
    "    lexicon.extend(ma.nouns(token))\n",
    "print(\"명사 분석 결과 : \", list(set(lexicon))) # 필요없는 중복값을 날리기 위해 set()에 담음 \n",
    "# 더 세밀한 분석을 위해 N-gram을 적용할 필요가 있다.\n",
    "\n",
    "lexicon.extend(ngramEojeol(\" \".join([token[0] for token in ma.pos(sentence)])))\n",
    "print(\"어절(바이그램) 분석 : \", list(set(lexicon)))\n",
    "\n",
    "newLexicon = list()\n",
    "for term in lexicon:\n",
    "    newLexicon.extend(ngramUmjeol(term))\n",
    "lexicon.extend([term for term in newLexicon if len(term.strip()) > th])\n",
    "print(\"음절(바이그램) 분석 : \", list(set(lexicon)))\n",
    "print(len(list(set(lexicon))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngramEojeol(sentence, n=2): # sentence를 받아 어절 단위로 분리해주는 함수\n",
    "    '''\n",
    "    입력:     단어1,   단어2,   단어3,  단어4 : 4\n",
    "    출력(2) : 단어12,  단어23,  단어34 :        3 - n + 1\n",
    "    출력(3) : 단어123, 단어234         :        2 - n + 1\n",
    "    '''\n",
    "    tokens = sentence.split()\n",
    "    ngram = []\n",
    "    \n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngram.append(' '.join(tokens[i:i + n]))    \n",
    "        \n",
    "    return ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngramUmjeol(term, n = 2): # 음절 단위로 구분하는 함수. sentence를 받아 2개(n=2)씩 쪼갠다.\n",
    "\n",
    "    ngram = []\n",
    "    \n",
    "    for i in range(len(term) - n + 1):\n",
    "        # ngram.append(tokens_ngram[i:i+n]) # 방법1\n",
    "        # ngram.append(tuple(tokens_ngram[i:i+n])) # 방법2 (튜플로 반환 시 키값을 쓸 수 있음)\n",
    "        ngram.append(''.join(term[i:i + n])) # 방법3\n",
    "        \n",
    "    return ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "# path = \"C:/Users/brsta/ICT_AI_AdvanceClass_NLP/0314_DownloadedNewstxts/\" (상대경로)\n",
    "# path = \"0314_DownloadedNewstxts\" (절대경로)\n",
    "\n",
    "# fileids() => 말뭉치 목록을 리턴. 이 함수처럼 getFileList라는 함수를 만들자.  \n",
    "def getFileList(base = \"./\", ext = \"txt\"): # 아무것도 안했다면 base는 현재 경로\n",
    "    fileList = list()\n",
    "    for file in listdir(base):\n",
    "        if file.split(\".\")[-1] == ext: # .을 기준으로 split한 것이 txt인지 검사\n",
    "            fileList.append(\"{0}/{1}\".format(base, file))\n",
    "            \n",
    "    return fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContent(file): # txt 컨텐츠를 편하게 읽어오기 위한 함수\n",
    "    with open(file, encoding=\"UTF-8\") as f:\n",
    "        content = f.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(getFileList(\"C:/Users/brsta/ICT_AI_AdvanceClass_NLP/0314_DownloadedNewstxts/\")) # 정상작동하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = getContent(getFileList(\"C:/Users/brsta/ICT_AI_AdvanceClass_NLP/0314_DownloadedNewstxts/\")[0]) # 정상작동하는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "'\\n\\n\\n\\n\\n// flash \\nfunction _flash_removeCallback() {}\\n\\n jawon1212@donga.com]\\n\\n'와 같이 거슬리는 단어를 정규식을 응용해 걸러낼 필요가 있다. \n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------\n1st pattern :  re.compile('[!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~]{2,}')\n1st findall result :  ['//', '()', '{}', '\"...']\n1st filtered result :  \n\n\n\n\n  flash 오류를 우회하기 위한 함수 추가\nfunction _flash_removeCallback   \n\n오히려 단체측 \"무선이어폰 연구는 존재치도 않아 국내 참여 연구자도 '어리둥절'이엠에프사이언티스에서 일부 언론 보도를 부정하며 직접 보내온 이메일 내용이다. 이엠에프사이언티스트 관계자인 조엘 모스코위츠 미국 버클리 캘리포니아대 가정사회건강연구소 소장은 무선 이어폰의 건강 유해성에 대한 보도를 부정했다. 고재원 기자 jawon1212@donga.com 18일 오전 전세계 과학자들이 애플 에어팟과 같은 무선 이어폰이 암 발생 위험을 키울 수 있다는 호소문을 국제연합(UN)과 세계보건기구(WHO)에 제출했다는 일부 국내외 언론의 보도가 나오면서 불안감이 확산되고 있다. 하지만 실제 이 단체와 호소문에 이름을 올린 과학자들에게 확인한 결과 호소문은 4년전 제출됐던 것이며 또 특정 제품이나 제조사를 언급하지 않은 것으로 확인됐다.18일 데일리메일과 중앙일보 등 국내외 일부 언론에 따르면 전 세계 과학자 247명이 무선 이어폰의 비이온화 전자기장(EMF)이 암을 유발할 위험 우려가 있다며 UN과 WHO에 호소문을 제출했다고 전했다.  이들 매체들은 호소문에 “애플 에어팟이 EMF에 관한 법적 기준치를 준수하고 있지만 장시간 노출될 경우 건강에 좋지 않을 수 있다”는 내용이 포함됐다고 보도했다.이들 매체들은 이 호소문에는 전 세계 42개국, 과학자 247명이 서명을 했다고 전했다. 여기에는 한국의 연세대, 한양대, 가톨릭대, 단국대, 중앙대, 경북대, 한림대 소속 과학자 15명의 이름도 포함됐다.   하지만 취재 결과 호소문 작성을 주도한 비영리단체 ‘이엠에프사이언티스트(EMFscientiest)’는 애플 에어팟과 같은 무선 이어폰에 대한 유해성을 주장하지 않은 것으로 확인됐다. 동아사이언스가 이엠에프사이언티스트에 직접 이메일로 확인한 결과 “일부 언론 보도가 호소문에 대한 부정확한 내용을 담고 있다”며 “무선 블루투스의 자기장에 머리가 장시간 노출될 시의 안정성에 대한 연구는 존재하지 않는다”고 밝혔다.이엠에프사이언티스트에 따르면 이 단체는 지난 2015년 5월 실제로 전세계 과학자 190명의 서명을 받아 UN과 WHO, 유엔환경계획(UNEP)에  ‘국제 EMF 과학자 호소문’을 제출하기는 했다. 당시 호소문에는 전세계 저명한 학술지에 게재된 2000개가 넘는 연구들을 근거로 비전리 전자기장 노출로부터 보호와 방지가 필요하다는 내용을 담았다.  이 단체는 지속적으로 해당 내용에 동의하는 과학자들의 서명을 받아 현재는 42개국 247명으로 늘어났다. 실제 한국인 과학자들 15명도 이 호소문에 서명한 것으로 확인됐다.이엠에프사이언티스 관계자인 조엘 모스코위츠 미국 버클리 캘리포니아대 가정사회건강연구소 소장은 이메일 인터뷰에서 “호소문에 서명한 과학자들은 저명한 학술지에 전자기장과 생물학, 건강과 관련된 연구를 발표한 분들”이라며 “하지만 호소문은 이번에 새로 제출된 내용이 아닌 2015년 5월 제출됐으며 특정 제품이나 제조사를 언급하고 있지 않다\"고 말했다.이 호소문에 서명했다고 알려진 송기원 연세대 생화학과 교수는 \"명단이 올라간 것도 잘 몰랐다”며 “최근 몇 년 동안 해당 주제에 관여하지 않았고 당시도 다른 교수가 서명하라 해 서명했다\"고 말했다. 또 다른 서명자인 한 지방국립대 교수는 \"대략 2년전 서명했던 기억이 난다\"고 말했다.전자기장 자체 유해성 여부는 아직까지 논란이 있다. WHO는 지난 30년간 2만5000개가 넘는 관련 연구들이 존재하지만 낮은 전자기장의 건강 유해성을 확인하지 못했다고 결론내렸다. 이덕환 서강대 화학과 교수는 \"통신용 마이크로파가 인체에 영향을 미치는지 여부는 이미 여러 연구를 통해 문제가 없다고 확실히 검증됐다\"며 \"이미 우리 주변에 수많은 통신용 마이크로파가 지나다니고 있는데 전화나 무선이어폰을 가까이 가져간다고 새삼 더 문제가 된다는 발상도 황당하다\"고 밝혔다. [고재원 기자  jawon1212@donga.com]\n\n\n------------------------------------------------------------------------------------------------------------------\n2nd pattern :  re.compile('[A-Za-z\\\\-\\\\_]{4,}')\n2nd findall result :  ['flash', 'function', '_flash_removeCallback', 'jawon', 'donga', 'EMFscientiest', 'UNEP', 'jawon', 'donga']\n2nd filtered result :  \n\n\n\n\n//   오류를 우회하기 위한 함수 추가\n   () {}\n\n오히려 단체측 \"무선이어폰 연구는 존재치도 않아\"...국내 참여 연구자도 '어리둥절'이엠에프사이언티스에서 일부 언론 보도를 부정하며 직접 보내온 이메일 내용이다. 이엠에프사이언티스트 관계자인 조엘 모스코위츠 미국 버클리 캘리포니아대 가정사회건강연구소 소장은 무선 이어폰의 건강 유해성에 대한 보도를 부정했다. 고재원 기자  1212@ .com 18일 오전 전세계 과학자들이 애플 에어팟과 같은 무선 이어폰이 암 발생 위험을 키울 수 있다는 호소문을 국제연합(UN)과 세계보건기구(WHO)에 제출했다는 일부 국내외 언론의 보도가 나오면서 불안감이 확산되고 있다. 하지만 실제 이 단체와 호소문에 이름을 올린 과학자들에게 확인한 결과 호소문은 4년전 제출됐던 것이며 또 특정 제품이나 제조사를 언급하지 않은 것으로 확인됐다.18일 데일리메일과 중앙일보 등 국내외 일부 언론에 따르면 전 세계 과학자 247명이 무선 이어폰의 비이온화 전자기장(EMF)이 암을 유발할 위험 우려가 있다며 UN과 WHO에 호소문을 제출했다고 전했다.  이들 매체들은 호소문에 “애플 에어팟이 EMF에 관한 법적 기준치를 준수하고 있지만 장시간 노출될 경우 건강에 좋지 않을 수 있다”는 내용이 포함됐다고 보도했다.이들 매체들은 이 호소문에는 전 세계 42개국, 과학자 247명이 서명을 했다고 전했다. 여기에는 한국의 연세대, 한양대, 가톨릭대, 단국대, 중앙대, 경북대, 한림대 소속 과학자 15명의 이름도 포함됐다.   하지만 취재 결과 호소문 작성을 주도한 비영리단체 ‘이엠에프사이언티스트( )’는 애플 에어팟과 같은 무선 이어폰에 대한 유해성을 주장하지 않은 것으로 확인됐다. 동아사이언스가 이엠에프사이언티스트에 직접 이메일로 확인한 결과 “일부 언론 보도가 호소문에 대한 부정확한 내용을 담고 있다”며 “무선 블루투스의 자기장에 머리가 장시간 노출될 시의 안정성에 대한 연구는 존재하지 않는다”고 밝혔다.이엠에프사이언티스트에 따르면 이 단체는 지난 2015년 5월 실제로 전세계 과학자 190명의 서명을 받아 UN과 WHO, 유엔환경계획( )에  ‘국제 EMF 과학자 호소문’을 제출하기는 했다. 당시 호소문에는 전세계 저명한 학술지에 게재된 2000개가 넘는 연구들을 근거로 비전리 전자기장 노출로부터 보호와 방지가 필요하다는 내용을 담았다.  이 단체는 지속적으로 해당 내용에 동의하는 과학자들의 서명을 받아 현재는 42개국 247명으로 늘어났다. 실제 한국인 과학자들 15명도 이 호소문에 서명한 것으로 확인됐다.이엠에프사이언티스 관계자인 조엘 모스코위츠 미국 버클리 캘리포니아대 가정사회건강연구소 소장은 이메일 인터뷰에서 “호소문에 서명한 과학자들은 저명한 학술지에 전자기장과 생물학, 건강과 관련된 연구를 발표한 분들”이라며 “하지만 호소문은 이번에 새로 제출된 내용이 아닌 2015년 5월 제출됐으며 특정 제품이나 제조사를 언급하고 있지 않다\"고 말했다.이 호소문에 서명했다고 알려진 송기원 연세대 생화학과 교수는 \"명단이 올라간 것도 잘 몰랐다”며 “최근 몇 년 동안 해당 주제에 관여하지 않았고 당시도 다른 교수가 서명하라 해 서명했다\"고 말했다. 또 다른 서명자인 한 지방국립대 교수는 \"대략 2년전 서명했던 기억이 난다\"고 말했다.전자기장 자체 유해성 여부는 아직까지 논란이 있다. WHO는 지난 30년간 2만5000개가 넘는 관련 연구들이 존재하지만 낮은 전자기장의 건강 유해성을 확인하지 못했다고 결론내렸다. 이덕환 서강대 화학과 교수는 \"통신용 마이크로파가 인체에 영향을 미치는지 여부는 이미 여러 연구를 통해 문제가 없다고 확실히 검증됐다\"며 \"이미 우리 주변에 수많은 통신용 마이크로파가 지나다니고 있는데 전화나 무선이어폰을 가까이 가져간다고 새삼 더 문제가 된다는 발상도 황당하다\"고 밝혔다. [고재원 기자   1212@ .com]\n\n\n------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from string import punctuation # !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~와 같은 불용어가 들어 있다. \n",
    "# 문자를 기입할때는 보통 []로 감싸서 사용. \n",
    "\n",
    "# 첫번째 필터링 : 특수문자 제거\n",
    "pattern = re.compile(r\"[%s]{2,}\" % re.escape(punctuation)) # punctuation 안의 특수문자가 두번이상 반복되는 모든 문자에 대해 패턴 정의 \n",
    "print(\"------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"1st pattern : \",  pattern) # 패턴이 잘 컴파일되었는지 확인 목적  \n",
    "print(\"1st findall result : \", pattern.findall(content)) # 패턴대로 잘 찾아지는지 확인 목적\n",
    "print(\"1st filtered result : \", pattern.sub(\" \", content)) # 정의된 패턴을 통해 2번이상 반복되는 특수 문자를 제거한 결과물(\" \"으로 치환한 결과) 출력\n",
    "print(\"------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# 두번째 필터링 : _flash_remoceCallback같은 거슬리는 문구 제거(보통 EMFscientiest와 같이 특별한 의미를 갖고 있는 영단어 때문에 사용하면 위험함)\n",
    "pattern = re.compile(r\"[A-Za-z\\-\\_]{4,}\") # 4글자 이상 반복되는 영어 문구 찾아내기\n",
    "print(\"2nd pattern : \",  pattern)\n",
    "print(\"2nd findall result : \", pattern.findall(content))\n",
    "print(\"2nd filtered result : \", pattern.sub(\" \", content))\n",
    "print(\"------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
